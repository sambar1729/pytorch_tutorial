{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM7sKHzCUPFoeqo3999OIxG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sambar1729/pytorch_tutorial/blob/main/pytorch_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8G-r90Rp7Y-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pytorch tutorial\n",
        "\n",
        "Following Sebastian Raschka's tutorial here: https://sebastianraschka.com/teaching/pytorch-1h/"
      ],
      "metadata": {
        "id": "CijvWyVOp-3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.4.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11e9J7WiqEze",
        "outputId": "bbed4e7c-d527-4b5a-a451-66ad90f44a3c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n",
            "  Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4.1)\n",
            "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.1) (1.3.0)\n",
            "Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.4.1 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.1 triton-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install memory-profiler\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDVwTKKa570-",
        "outputId": "a370b314-7493-4f6f-eab4-1348e3ad667c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting memory-profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from memory-profiler) (5.9.5)\n",
            "Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hioDYMINqLqA",
        "outputId": "7e94347c-e913-4312-c066-725c876648ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.4.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor0d = torch.tensor(1)"
      ],
      "metadata": {
        "id": "IRZ9wKbcrVBs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1d = torch.tensor([1, 2, 3])"
      ],
      "metadata": {
        "id": "FidKa9y0rYcY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d = torch.tensor([[1, 2], [3, 4]])"
      ],
      "metadata": {
        "id": "In0liAMmuhIS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])"
      ],
      "metadata": {
        "id": "c-Hd8bGgujZP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1d = torch.tensor([1, 2, 3])\n",
        "\n",
        "print(tensor1d.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCnEkI-QulfM",
        "outputId": "5c03d3aa-d738-4a34-ed0d-f7017494dc38"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "floatvec = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(floatvec.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDt4n-B2vmrQ",
        "outputId": "7ddbe371-b0dd-4d1a-ae71-6454edbfa354"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "floatvec = tensor1d.to(torch.float32)\n",
        "print(floatvec.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laceExhIv0b9",
        "outputId": "6486885a-3fbf-45da-ed80-7ca02962e396"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7NMaGFYwRG7",
        "outputId": "79e03df4-b390-4ef3-c989-8a726b07a667"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d = torch.tensor([[1, 2, 3],\n",
        "                         [4, 5, 6]])"
      ],
      "metadata": {
        "id": "eJR0Cmw2xavu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWTqmRWoxfDx",
        "outputId": "76556980-ecbb-4a27-a86c-d10c6e3159fd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d.reshape([3, 2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckRbNNk_xgBC",
        "outputId": "09f23a20-aea2-440c-aa16-75c51c5700da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d.view(3,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ3HZveGxikM",
        "outputId": "26372708-31ab-48c0-89d5-a0fb1feb78b6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pQmFmodxpMm",
        "outputId": "ab4ec2c9-a176-486b-96fc-03a6948424db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcZupoFtx05G",
        "outputId": "ad684040-1cf4-4bc2-93c8-4727c8f4b93c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4],\n",
              "        [2, 5],\n",
              "        [3, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d.matmul(tensor2d.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Dd4AOX3x2JR",
        "outputId": "66430aa3-f097-4b6f-eeb8-2097d984b1e0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14, 32],\n",
              "        [32, 77]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d @ tensor2d.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxb8Jgdax56D",
        "outputId": "fa33ab2b-14ac-4ccc-b089-573d3bfae383"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14, 32],\n",
              "        [32, 77]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "y = torch.tensor([1.0])  # true label\n",
        "x1 = torch.tensor([1.1]) # input feature\n",
        "w1 = torch.tensor([2.2]) # weight parameter\n",
        "b = torch.tensor([0.0])  # bias unit\n",
        "\n",
        "z = x1 * w1 + b          # net input\n",
        "a = torch.sigmoid(z)     # activation & output\n",
        "\n",
        "loss = F.binary_cross_entropy(a, y)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "xG1BrB3tx8UM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161e420b-86c9-46d4-e238-4521ab9b458b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0852)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "\n",
        "model = nn.Linear(10, 1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "data = torch.randn(4, 10)\n",
        "target = torch.randn(4, 1)\n",
        "\n",
        "for epoch in range(100):\n",
        "    output = model(data)\n",
        "    loss = nn.functional.mse_loss(output, target)\n",
        "    loss.backward()\n",
        "    # BUG: missing optimizer.zero_grad()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch} loss grad sum:\", sum(p.grad.sum().item() for p in model.parameters()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOuux6K80nXp",
        "outputId": "ac28c52b-42da-4658-ecca-cf65a7c1a272"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 loss grad sum: 5.941392242908478\n",
            "Epoch 1 loss grad sum: 11.378333985805511\n",
            "Epoch 2 loss grad sum: 15.853800415992737\n",
            "Epoch 3 loss grad sum: 19.000988602638245\n",
            "Epoch 4 loss grad sum: 20.57731395959854\n",
            "Epoch 5 loss grad sum: 20.48631116747856\n",
            "Epoch 6 loss grad sum: 18.785321831703186\n",
            "Epoch 7 loss grad sum: 15.678302884101868\n",
            "Epoch 8 loss grad sum: 11.494457006454468\n",
            "Epoch 9 loss grad sum: 6.654939651489258\n",
            "Epoch 10 loss grad sum: 1.630887508392334\n",
            "Epoch 11 loss grad sum: -3.1029887199401855\n",
            "Epoch 12 loss grad sum: -7.114686965942383\n",
            "Epoch 13 loss grad sum: -10.056479930877686\n",
            "Epoch 14 loss grad sum: -11.697687149047852\n",
            "Epoch 15 loss grad sum: -11.945482730865479\n",
            "Epoch 16 loss grad sum: -10.851707696914673\n",
            "Epoch 17 loss grad sum: -8.605173110961914\n",
            "Epoch 18 loss grad sum: -5.510236501693726\n",
            "Epoch 19 loss grad sum: -1.9539647102355957\n",
            "Epoch 20 loss grad sum: 1.6348085403442383\n",
            "Epoch 21 loss grad sum: 4.830343008041382\n",
            "Epoch 22 loss grad sum: 7.254231214523315\n",
            "Epoch 23 loss grad sum: 8.614570617675781\n",
            "Epoch 24 loss grad sum: 8.736126899719238\n",
            "Epoch 25 loss grad sum: 7.578460693359375\n",
            "Epoch 26 loss grad sum: 5.240239143371582\n",
            "Epoch 27 loss grad sum: 1.9493255615234375\n",
            "Epoch 28 loss grad sum: -1.9603521823883057\n",
            "Epoch 29 loss grad sum: -6.082745313644409\n",
            "Epoch 30 loss grad sum: -9.981050491333008\n",
            "Epoch 31 loss grad sum: -13.23228645324707\n",
            "Epoch 32 loss grad sum: -15.470582246780396\n",
            "Epoch 33 loss grad sum: -16.42482841014862\n",
            "Epoch 34 loss grad sum: -15.946880221366882\n",
            "Epoch 35 loss grad sum: -14.027485191822052\n",
            "Epoch 36 loss grad sum: -10.79832911491394\n",
            "Epoch 37 loss grad sum: -6.519991159439087\n",
            "Epoch 38 loss grad sum: -1.5570265054702759\n",
            "Epoch 39 loss grad sum: 3.6573405265808105\n",
            "Epoch 40 loss grad sum: 8.663355588912964\n",
            "Epoch 41 loss grad sum: 13.019495725631714\n",
            "Epoch 42 loss grad sum: 16.345381498336792\n",
            "Epoch 43 loss grad sum: 18.358529806137085\n",
            "Epoch 44 loss grad sum: 18.901339530944824\n",
            "Epoch 45 loss grad sum: 17.955564498901367\n",
            "Epoch 46 loss grad sum: 15.642943620681763\n",
            "Epoch 47 loss grad sum: 12.211915969848633\n",
            "Epoch 48 loss grad sum: 8.011823892593384\n",
            "Epoch 49 loss grad sum: 3.4572439193725586\n",
            "Epoch 50 loss grad sum: -1.0139319896697998\n",
            "Epoch 51 loss grad sum: -4.984421253204346\n",
            "Epoch 52 loss grad sum: -8.099037647247314\n",
            "Epoch 53 loss grad sum: -10.099567651748657\n",
            "Epoch 54 loss grad sum: -10.849509119987488\n",
            "Epoch 55 loss grad sum: -10.346242368221283\n",
            "Epoch 56 loss grad sum: -8.71938967704773\n",
            "Epoch 57 loss grad sum: -6.215615510940552\n",
            "Epoch 58 loss grad sum: -3.1714253425598145\n",
            "Epoch 59 loss grad sum: 0.023212432861328125\n",
            "Epoch 60 loss grad sum: 2.966693878173828\n",
            "Epoch 61 loss grad sum: 5.288759231567383\n",
            "Epoch 62 loss grad sum: 6.690216064453125\n",
            "Epoch 63 loss grad sum: 6.975297927856445\n",
            "Epoch 64 loss grad sum: 6.073345184326172\n",
            "Epoch 65 loss grad sum: 4.0475172996521\n",
            "Epoch 66 loss grad sum: 1.0895943641662598\n",
            "Epoch 67 loss grad sum: -2.498662233352661\n",
            "Epoch 68 loss grad sum: -6.335761785507202\n",
            "Epoch 69 loss grad sum: -9.999331951141357\n",
            "Epoch 70 loss grad sum: -13.069633841514587\n",
            "Epoch 71 loss grad sum: -15.173378586769104\n",
            "Epoch 72 loss grad sum: -16.023348450660706\n",
            "Epoch 73 loss grad sum: -15.449785947799683\n",
            "Epoch 74 loss grad sum: -13.420307874679565\n",
            "Epoch 75 loss grad sum: -10.046230435371399\n",
            "Epoch 76 loss grad sum: -5.574533939361572\n",
            "Epoch 77 loss grad sum: -0.36616063117980957\n",
            "Epoch 78 loss grad sum: 5.137285113334656\n",
            "Epoch 79 loss grad sum: 10.45522689819336\n",
            "Epoch 80 loss grad sum: 15.114096641540527\n",
            "Epoch 81 loss grad sum: 18.693092226982117\n",
            "Epoch 82 loss grad sum: 20.865131378173828\n",
            "Epoch 83 loss grad sum: 21.428996801376343\n",
            "Epoch 84 loss grad sum: 20.32938861846924\n",
            "Epoch 85 loss grad sum: 17.662895917892456\n",
            "Epoch 86 loss grad sum: 13.669232845306396\n",
            "Epoch 87 loss grad sum: 8.708560466766357\n",
            "Epoch 88 loss grad sum: 3.2270933389663696\n",
            "Epoch 89 loss grad sum: -2.2856435775756836\n",
            "Epoch 90 loss grad sum: -7.343720436096191\n",
            "Epoch 91 loss grad sum: -11.51124906539917\n",
            "Epoch 92 loss grad sum: -14.443818092346191\n",
            "Epoch 93 loss grad sum: -15.920833587646484\n",
            "Epoch 94 loss grad sum: -15.865576267242432\n",
            "Epoch 95 loss grad sum: -14.35107421875\n",
            "Epoch 96 loss grad sum: -11.591155290603638\n",
            "Epoch 97 loss grad sum: -7.9176952838897705\n",
            "Epoch 98 loss grad sum: -3.746284008026123\n",
            "Epoch 99 loss grad sum: 0.46622657775878906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "\n",
        "model = nn.Linear(10, 1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "data = torch.randn(4, 10)\n",
        "target = torch.randn(4, 1)\n",
        "\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = nn.functional.mse_loss(output, target)\n",
        "    loss.backward()\n",
        "    # optimizer.zero_grad()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch} loss grad sum:\", sum(p.grad.sum().item() for p in model.parameters()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-dWjMdJ0n1a",
        "outputId": "31c37d2b-674f-4df8-a167-ed5dd75eb8a6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 loss grad sum: -15.222372055053711\n",
            "Epoch 1 loss grad sum: -14.585453748703003\n",
            "Epoch 2 loss grad sum: -13.971067905426025\n",
            "Epoch 3 loss grad sum: -13.378954410552979\n",
            "Epoch 4 loss grad sum: -12.80876612663269\n",
            "Epoch 5 loss grad sum: -12.260099411010742\n",
            "Epoch 6 loss grad sum: -11.73249864578247\n",
            "Epoch 7 loss grad sum: -11.225463390350342\n",
            "Epoch 8 loss grad sum: -10.738462448120117\n",
            "Epoch 9 loss grad sum: -10.270942687988281\n",
            "Epoch 10 loss grad sum: -9.82233214378357\n",
            "Epoch 11 loss grad sum: -9.392048954963684\n",
            "Epoch 12 loss grad sum: -8.979502558708191\n",
            "Epoch 13 loss grad sum: -8.584102034568787\n",
            "Epoch 14 loss grad sum: -8.205257415771484\n",
            "Epoch 15 loss grad sum: -7.842382311820984\n",
            "Epoch 16 loss grad sum: -7.494899153709412\n",
            "Epoch 17 loss grad sum: -7.162235975265503\n",
            "Epoch 18 loss grad sum: -6.843834161758423\n",
            "Epoch 19 loss grad sum: -6.53914475440979\n",
            "Epoch 20 loss grad sum: -6.247633457183838\n",
            "Epoch 21 loss grad sum: -5.9687793254852295\n",
            "Epoch 22 loss grad sum: -5.702076196670532\n",
            "Epoch 23 loss grad sum: -5.447030782699585\n",
            "Epoch 24 loss grad sum: -5.203167080879211\n",
            "Epoch 25 loss grad sum: -4.970024585723877\n",
            "Epoch 26 loss grad sum: -4.747156500816345\n",
            "Epoch 27 loss grad sum: -4.534131705760956\n",
            "Epoch 28 loss grad sum: -4.330535709857941\n",
            "Epoch 29 loss grad sum: -4.135967314243317\n",
            "Epoch 30 loss grad sum: -3.950041174888611\n",
            "Epoch 31 loss grad sum: -3.772387146949768\n",
            "Epoch 32 loss grad sum: -3.602648615837097\n",
            "Epoch 33 loss grad sum: -3.440480887889862\n",
            "Epoch 34 loss grad sum: -3.285557746887207\n",
            "Epoch 35 loss grad sum: -3.1375615000724792\n",
            "Epoch 36 loss grad sum: -2.9961880445480347\n",
            "Epoch 37 loss grad sum: -2.8611491918563843\n",
            "Epoch 38 loss grad sum: -2.732164144515991\n",
            "Epoch 39 loss grad sum: -2.608966827392578\n",
            "Epoch 40 loss grad sum: -2.491300582885742\n",
            "Epoch 41 loss grad sum: -2.3789215683937073\n",
            "Epoch 42 loss grad sum: -2.2715930938720703\n",
            "Epoch 43 loss grad sum: -2.1690915524959564\n",
            "Epoch 44 loss grad sum: -2.0712019205093384\n",
            "Epoch 45 loss grad sum: -1.9777186512947083\n",
            "Epoch 46 loss grad sum: -1.888445645570755\n",
            "Epoch 47 loss grad sum: -1.8031927645206451\n",
            "Epoch 48 loss grad sum: -1.7217814028263092\n",
            "Epoch 49 loss grad sum: -1.644038051366806\n",
            "Epoch 50 loss grad sum: -1.5698001682758331\n",
            "Epoch 51 loss grad sum: -1.498908907175064\n",
            "Epoch 52 loss grad sum: -1.4312148094177246\n",
            "Epoch 53 loss grad sum: -1.3665741384029388\n",
            "Epoch 54 loss grad sum: -1.3048476874828339\n",
            "Epoch 55 loss grad sum: -1.245906800031662\n",
            "Epoch 56 loss grad sum: -1.1896256506443024\n",
            "Epoch 57 loss grad sum: -1.1358826458454132\n",
            "Epoch 58 loss grad sum: -1.084565132856369\n",
            "Epoch 59 loss grad sum: -1.035563439130783\n",
            "Epoch 60 loss grad sum: -0.9887720942497253\n",
            "Epoch 61 loss grad sum: -0.9440930187702179\n",
            "Epoch 62 loss grad sum: -0.9014299213886261\n",
            "Epoch 63 loss grad sum: -0.8606923222541809\n",
            "Epoch 64 loss grad sum: -0.8217924237251282\n",
            "Epoch 65 loss grad sum: -0.7846481800079346\n",
            "Epoch 66 loss grad sum: -0.7491800785064697\n",
            "Epoch 67 loss grad sum: -0.7153118550777435\n",
            "Epoch 68 loss grad sum: -0.6829729974269867\n",
            "Epoch 69 loss grad sum: -0.6520932018756866\n",
            "Epoch 70 loss grad sum: -0.6226064562797546\n",
            "Epoch 71 loss grad sum: -0.5944497287273407\n",
            "Epoch 72 loss grad sum: -0.5675636231899261\n",
            "Epoch 73 loss grad sum: -0.5418908298015594\n",
            "Epoch 74 loss grad sum: -0.5173757672309875\n",
            "Epoch 75 loss grad sum: -0.4939660429954529\n",
            "Epoch 76 loss grad sum: -0.4716131091117859\n",
            "Epoch 77 loss grad sum: -0.4502676725387573\n",
            "Epoch 78 loss grad sum: -0.4298843443393707\n",
            "Epoch 79 loss grad sum: -0.41042184829711914\n",
            "Epoch 80 loss grad sum: -0.3918359577655792\n",
            "Epoch 81 loss grad sum: -0.3740886449813843\n",
            "Epoch 82 loss grad sum: -0.35714149475097656\n",
            "Epoch 83 loss grad sum: -0.34095992147922516\n",
            "Epoch 84 loss grad sum: -0.32550549507141113\n",
            "Epoch 85 loss grad sum: -0.31075018644332886\n",
            "Epoch 86 loss grad sum: -0.29665905237197876\n",
            "Epoch 87 loss grad sum: -0.2832042872905731\n",
            "Epoch 88 loss grad sum: -0.2703540623188019\n",
            "Epoch 89 loss grad sum: -0.25808607041835785\n",
            "Epoch 90 loss grad sum: -0.2463676631450653\n",
            "Epoch 91 loss grad sum: -0.23517996072769165\n",
            "Epoch 92 loss grad sum: -0.22449560463428497\n",
            "Epoch 93 loss grad sum: -0.21429435908794403\n",
            "Epoch 94 loss grad sum: -0.20455120503902435\n",
            "Epoch 95 loss grad sum: -0.19524911046028137\n",
            "Epoch 96 loss grad sum: -0.18636509031057358\n",
            "Epoch 97 loss grad sum: -0.17788174003362656\n",
            "Epoch 98 loss grad sum: -0.16978125274181366\n",
            "Epoch 99 loss grad sum: -0.16204551607370377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "y = torch.tensor([1.0])  # true label\n",
        "x1 = torch.tensor([1.1]) # input feature\n",
        "w1 = torch.tensor([2.2]) # weight parameter\n",
        "b = torch.tensor([0.0])  # bias unit\n",
        "\n",
        "z = x1 * w1 + b          # net input\n",
        "a = torch.sigmoid(z)     # activation & output\n",
        "\n",
        "loss = F.binary_cross_entropy(a, y)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROeTL35p03SO",
        "outputId": "e7c2c26f-9105-4789-c79f-418834725e7a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0852)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VgDNJLIM1gy-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# Dataloaders"
      ],
      "metadata": {
        "id": "V5e41wWL4f2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = torch.nn.Sequential(\n",
        "\n",
        "            # 1st hidden layer\n",
        "            torch.nn.Linear(num_inputs, 30),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # 2nd hidden layer\n",
        "            torch.nn.Linear(30, 20),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # output layer\n",
        "            torch.nn.Linear(20, num_outputs),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.layers(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "eoeYUkGxi-E4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork(50, 3)"
      ],
      "metadata": {
        "id": "umWVEvh5jDPb"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTGkRWVnjKGl",
        "outputId": "05d8f1e1-ef38-48a2-cfcd-8e8a88814459"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_params = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad\n",
        ")\n",
        "print(\"Total number of trainable model parameters:\", num_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiHT4KVyjL2f",
        "outputId": "e3163ed4-2d13-419b-f1aa-a96ddcbc8ee9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable model parameters: 2213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor([\n",
        "    [-1.2, 3.1],\n",
        "    [-0.9, 2.9],\n",
        "    [-0.5, 2.6],\n",
        "    [2.3, -1.1],\n",
        "    [2.7, -1.5]\n",
        "])\n",
        "\n",
        "y_train = torch.tensor([0, 0, 0, 1, 1])"
      ],
      "metadata": {
        "id": "TNKktQWRnNow"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkhPmGWA0fV4",
        "outputId": "7e57699b-819d-42bc-864e-99a8a30dd2a4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHpzW17X0gJE",
        "outputId": "3ea8a81a-4629-453d-fb23-7890448d3823"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = torch.tensor([\n",
        "    [-0.8, 2.8],\n",
        "    [2.6, -1.6],\n",
        "])\n",
        "\n",
        "y_test = torch.tensor([0, 1])"
      ],
      "metadata": {
        "id": "tBJzmxLx0hLn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class ToyDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.features = X\n",
        "        self.labels = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        one_x = self.features[index]\n",
        "        one_y = self.labels[index]\n",
        "        return one_x, one_y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.shape[0]\n",
        "\n",
        "train_ds = ToyDataset(X_train, y_train)\n",
        "test_ds = ToyDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "BfmJEgj_0jmn"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoFIYE8f0oxF",
        "outputId": "0aab4f1c-cbd8-41c0-90cd-0e46022697d7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# train_loader = DataLoader(\n",
        "#     dataset=train_ds,\n",
        "#     batch_size=2,\n",
        "#     shuffle=True,\n",
        "#     num_workers=0\n",
        "# )\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    drop_last=True\n",
        ")"
      ],
      "metadata": {
        "id": "r_Bkllm42zlc"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2UQR80s263Y",
        "outputId": "60f857f3-dca6-47d9-f388-9a26c6c71db5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7daf559127d0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = ToyDataset(X_test, y_test)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "GakVwQ5K3F8s"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (x, y) in enumerate(train_loader):\n",
        "    print(f\"Batch {idx+1}:\", x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VglDAJ1M3I_b",
        "outputId": "4cca667f-7b93-4f09-dda5-f17d473c3957"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: tensor([[ 2.3000, -1.1000],\n",
            "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
            "Batch 2: tensor([[-1.2000,  3.1000],\n",
            "        [-0.5000,  2.6000]]) tensor([0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (x, y) in enumerate(train_loader):\n",
        "    print(f\"Batch {idx+1}:\", x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kBdYKBL3NSt",
        "outputId": "ef632d18-1d6a-4abc-db3e-b1b9113e0d63"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: tensor([[-1.2000,  3.1000],\n",
            "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
            "Batch 2: tensor([[ 2.3000, -1.1000],\n",
            "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
            "Batch 3: tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (x, y) in enumerate(train_loader):\n",
        "    print(f\"Batch {idx+1}:\", x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yTD9CfQ3ZPs",
        "outputId": "0f53502a-57f4-4e33-fcac-66bd87075fd3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: tensor([[-0.9000,  2.9000],\n",
            "        [ 2.3000, -1.1000]]) tensor([0, 1])\n",
            "Batch 2: tensor([[ 2.7000, -1.5000],\n",
            "        [-0.5000,  2.6000]]) tensor([1, 0])\n",
            "Batch 3: tensor([[-1.2000,  3.1000]]) tensor([0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, psutil\n",
        "\n",
        "proc = psutil.Process(os.getpid())\n",
        "mem_bytes = proc.memory_info().rss  # in bytes\n",
        "print(f\"RSS memory: {mem_bytes/1e9:.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1S__54F3eno",
        "outputId": "b36185c7-ed29-4bea-f7a3-fbfb87fe2967"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RSS memory: 0.56 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(torch.cuda.memory_summary())     # overall summary\n",
        "print(torch.cuda.memory_allocated())   # bytes currently allocated by tensors\n",
        "print(torch.cuda.memory_reserved())    # bytes reserved by caching allocator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPd6LhcZ5zHF",
        "outputId": "cac4e6d6-ecc4-4f93-9e4f-2ed215b959e3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moFHsc_56C-M",
        "outputId": "0a34edb5-b6f7-4a1c-82ea-ce55194e3496"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul  8 16:40:01 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > gpu_hammer.py << 'EOF'\n",
        "import torch, time\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "N = 4096\n",
        "a = torch.randn((N, N), device=device)\n",
        "b = torch.randn((N, N), device=device)\n",
        "\n",
        "iter_num = 0\n",
        "while True:\n",
        "    iter_num += 1\n",
        "    c = torch.mm(a, b)\n",
        "    # burn CPU/GPU a bit less if you like:\n",
        "    time.sleep(0.1)\n",
        "    if iter_num % 50 == 0:\n",
        "        print(f\"[Hammer #{iter_num}] GPU mem used: {torch.cuda.memory_allocated()/1e6:.1f} MB\")\n",
        "EOF"
      ],
      "metadata": {
        "id": "mZGoA1MH6JEM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# start the hammer in the background, unbuffered, logging to gpu.log\n",
        "nohup python3 -u gpu_hammer.py > gpu.log 2>&1 &\n",
        "\n",
        "# immediately capture its PID\n",
        "echo $! > gpu_hammer.pid\n",
        "\n",
        "echo \"Started gpu_hammer.py with PID $(cat gpu_hammer.pid)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjMbnLyq6sjZ",
        "outputId": "8d3d93fc-a1f0-4296-eb78-54deb154428c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started gpu_hammer.py with PID 10067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tXgUCO5n7lSy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}